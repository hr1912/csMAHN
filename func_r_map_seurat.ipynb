{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "819dd657-f081-4a5f-ac6a-573f554a40a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# func_r_map_seurat\n",
    "\n",
    "最后更新时间2024年4月11日\n",
    "\n",
    "Seurat 5.0.1的标签转移和UMAP坐标映射\n",
    "\n",
    "其中`Map_Seurat_normalize`和`Map_Seurat_cluster`已经实现了单细胞处理的标准流程\n",
    "\n",
    "\n",
    "+ seurat_to_mtx\n",
    "+ Map_Seurat_normalize\n",
    "+ Map_Seurat_cluster\n",
    "+ Map_Seurat_cluster_run_harmony\n",
    "+ Map_Seurat_mapquery\n",
    "+ Map_Seurat_example\n",
    "+ precess_after_Seurat\n",
    "+ run_Seurat\n",
    "\n",
    "```bash\n",
    "conda activate\n",
    "cd ~/link/res_publish\n",
    "jupyter nbconvert func_r_map_seurat.ipynb --to python\n",
    "mv func_r_map_seurat.py func_r_map_seurat.r\n",
    "echo \"finish\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb56cadb-afa6-46b4-8d79-7f40e3e41550",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdplyr    \u001b[39m 1.1.4     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.5\n",
      "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2  \u001b[39m 3.5.0     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.2.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.3     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.0.2     \n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n",
      "Loading required package: SeuratObject\n",
      "\n",
      "Loading required package: sp\n",
      "\n",
      "‘SeuratObject’ was built under R 4.3.2 but the current version is\n",
      "4.3.3; it is recomended that you reinstall ‘SeuratObject’ as the ABI\n",
      "for R may have changed\n",
      "\n",
      "‘SeuratObject’ was built with package ‘Matrix’ 1.6.3 but the current\n",
      "version is 1.6.5; it is recomended that you reinstall ‘SeuratObject’ as\n",
      "the ABI for ‘Matrix’ may have changed\n",
      "\n",
      "\n",
      "Attaching package: ‘SeuratObject’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    intersect\n",
      "\n",
      "\n",
      "Loading required package: Rcpp\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(Seurat)\n",
    "library(harmony)\n",
    "p_root = file.path('~/link/res_publish')\n",
    "p_run = file.path(p_root,'run')\n",
    "p_res = file.path(p_root,'res')\n",
    "p_cache = file.path(p_run,'cache')\n",
    "p_df_varmap = file.path(p_root,\"homo/df_varmap.csv\")\n",
    "if(! file.exists(p_df_varmap)){\n",
    "    stop(sprintf('[not exists] %s\\n',p_df_varmap))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56061430-00fa-49cc-86b0-89844cccd016",
   "metadata": {},
   "source": [
    "# other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "813762e5-aeab-4182-a02b-e1b348ed4f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_path_varmap <- function(q_sp_ref, q_sp_que, df_varmap_path = p_df_varmap ) {\n",
    "    df_varmap <- read.csv(df_varmap_path)\n",
    "    filtered_rows <- df_varmap %>%\n",
    "        filter(sp_ref == q_sp_ref & sp_que == q_sp_que)\n",
    "    \n",
    "    # 唯一匹配项\n",
    "    if (! nrow(filtered_rows) == 1) {\n",
    "        stop(\"[get path] Cannot get specified and unique path\\nq_sp_ref\\tq_sp_que\\n\", q_sp_ref, \"\\t\", q_sp_que)\n",
    "    }\n",
    "    path_varmap <- file.path(filtered_rows$path[1])\n",
    "    # isAbsolut\n",
    "    if(! str_detect('^/',path_varmap)){\n",
    "        path_varmap <- file.path(dirname(p_df_varmap),path_varmap)\n",
    "    }\n",
    "    # 存在\n",
    "    if (!file.exists(path_varmap)) {\n",
    "        stop(\"[not exists] \", as.character(path_varmap))\n",
    "    }\n",
    "\n",
    "    return(path_varmap)\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "show_ = function(obj,tag = ''){\n",
    "    cat(sprintf('%s--------------------\\n',tag))\n",
    "    cat(sprintf(\"\\t%s %s\\n\",typeof(obj),class(obj)))\n",
    "    if(typeof(obj) == 'S4'){cat('\\t@',slotNames(obj),'\\n')}\n",
    "    if(obj %>% names %>% length > 5){\n",
    "        cat('\\t$',names((obj)) %>% head(5) ,\n",
    "        sprintf(\"[names lenght] %d\",\n",
    "        obj %>% names %>% length) ,'\\n')    \n",
    "    }else{\n",
    "        cat('\\t$',names((obj)),'\\n')    \n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "savefig  <- function(fig, fig_name, p_plot = p_plot,\n",
    "                     height_ratio = 4, width_ratio = 4) {\n",
    "  if (!dir.exists(p_plot_item)) {\n",
    "    stop(sprintf(\"[Error][not exists] %s\", p_plot))\n",
    "  }\n",
    "  file.path(p_plot, fig_name) %>%\n",
    "    ggsave(fig, dpi = 200, bg = \"transparent\",\n",
    "      width = 200 * width_ratio, height = 200 * height_ratio,\n",
    "      units = \"px\")\n",
    "  cat(sprintf(\"[out][plot] %s\n",
    "\\tin %s\n",
    "\", fig_name, p_plot))\n",
    "}\n",
    "\n",
    "seurat_metadata_leftjoin = function(metadata,join_data,by,key_cell_name='cell_name'){\n",
    "    if(! key_cell_name %in% colnames(metadata)){\n",
    "        stop(sprintf(\"[Error] '%s' not in metadata\\n\",key_cell_name))\n",
    "    }\n",
    "    metadata = metadata %>% left_join(join_data,by = by)\n",
    "    rownames(metadata) = metadata[[key_cell_name]]\n",
    "    return(metadata)\n",
    "}\n",
    "\n",
    "seurat_gene_detect = function(adata,detect_regex){\n",
    "    temp = adata@assays$RNA@features %>% as.data.frame\n",
    "    temp = temp %>% mutate( gene = rownames(temp))\n",
    "    temp = temp %>% filter(str_detect(gene,detect_regex))\n",
    "    return(temp)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47919c11-715f-4d4f-88aa-5a0a42e44e8e",
   "metadata": {},
   "source": [
    "# seurat_to_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea5eaf34-8a71-4065-8432-c93fe943197c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seurat_to_mtx <- function(adata, p_dir, prefixes = \"\") {\n",
    "  if (!dir.exists(p_dir)) {\n",
    "    dir.create(p_dir, recursive = T)\n",
    "  }\n",
    "\n",
    "  sparse <- Matrix(adata@assays$RNA@layers$counts, sparse = T)\n",
    "\n",
    "  # [out] genes.tsv\n",
    "  df_genes <- adata@assays$RNA@features %>% as.data.frame()\n",
    "  df_genes <- df_genes %>%\n",
    "    transmute(\n",
    "      gene_names = rownames(df_genes),\n",
    "      gene_ids = ifelse(\"gene_ids\" %in% colnames(df_genes), gene_ids, gene_names)\n",
    "    ) %>%\n",
    "    select(gene_ids, gene_names)\n",
    "  df_genes %>% write.table(file.path(p_dir, sprintf(\"%sgenes.tsv\", prefixes)),\n",
    "    row.names = F, col.names = F, sep = \"\\t\", fileEncoding = \"utf-8\"\n",
    "  )\n",
    "\n",
    "  # [out] barcodes.tsv obs.csv\n",
    "  tibble(barcodes = rownames(adata@assays$RNA@cells)) %>% write.table(file.path(p_dir, sprintf(\"%sbarcodes.tsv\", prefixes)),\n",
    "    row.names = F, col.names = F, sep = \"\\t\", fileEncoding = \"utf-8\"\n",
    "  )\n",
    "  if (adata@meta.data %>% select(-orig.ident, -`nCount_RNA`, -`nFeature_RNA`) %>% colnames() %>% length() > 0) {\n",
    "    adata@meta.data %>% write.csv(file.path(p_dir, sprintf(\"%sobs.csv\", prefixes)),\n",
    "      row.names = T,\n",
    "      col.names = T,\n",
    "      fileEncoding = \"utf-8\"\n",
    "    )\n",
    "  }\n",
    "\n",
    "  # [out] matrix.mx\n",
    "  writeMM(sparse, file = file.path(p_dir, sprintf(\"%smatrix.mtx\", prefixes)))\n",
    "  cat(sprintf(\"[out] %s\", p_dir))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca88c5f-8a72-4670-b6a0-f2bf185aef36",
   "metadata": {},
   "source": [
    "# Map Seurat corss speciese\n",
    "\n",
    "## Method of came's article\n",
    "\n",
    "For Seurat V3, we\n",
    "\n",
    "+ input the raw data;\n",
    "+ used the default normalize process by NormalizeData() function;\n",
    "+ extracted the **top 2000 HVGs** by its FindVariableFeatures() function for reference and query, respectively;\n",
    "+ 【？】and performed further annotation process as described in its documentation "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5289c226-c713-4f9f-8c8c-e8549978414e",
   "metadata": {},
   "source": [
    "# Seurat flow\n",
    "\n",
    "## Map_Seurat_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d9e10ea-cf25-496a-b9f2-7d433ba81dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Map_Seurat_normalize <- function(adata, hvg_nfeatures = 2000, run_scale = TRUE, run_pca = TRUE, verbose = FALSE) {\n",
    "  # R 的形参不是引用，而是完全复制了一份\n",
    "  adata <- NormalizeData(adata, verbose = verbose)\n",
    "  adata <- FindVariableFeatures(adata, verbose = verbose, nfeatures = hvg_nfeatures)\n",
    "  if (run_scale) {\n",
    "    adata <- ScaleData(adata, verbose = verbose)\n",
    "  }\n",
    "  if (run_scale & run_pca) {\n",
    "    adata <- RunPCA(adata, verbose = verbose)\n",
    "    print(ElbowPlot(adata, ndims = 50))\n",
    "  }\n",
    "  return(adata)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e094a15-d64e-488c-9db9-64ee537be0e6",
   "metadata": {},
   "source": [
    "## Map_Seurat_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ba16d9b-fd8a-47fa-b604-0e32a91bea6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Map_Seurat_cluster =  function(adata,dims,resolution,key_celltype=NULL,verbose=FALSE){\n",
    "    adata <- FindNeighbors(adata,\n",
    "      dims = dims, verbose = verbose\n",
    "    )\n",
    "    adata <- FindClusters(adata, resolution = resolution, verbose = verbose)\n",
    "    # 返回umap model，后续的Running UMAP projection 需要umap model\n",
    "    adata <- RunUMAP(adata, dims = dims,verbose = verbose,return.model = TRUE)\n",
    "    if(!is_null(key_celltype)){\n",
    "        print(DimPlot(adata, group.by = c(key_celltype), reduction = \"umap\"))    \n",
    "    }\n",
    "    print(DimPlot(adata, group.by = c(\"seurat_clusters\"), reduction = \"umap\"))\n",
    "    \n",
    "    return(adata)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ca64c0-aeb6-4d7d-a84f-1de7eb3fc552",
   "metadata": {},
   "source": [
    "## Map_Seurat_cluster_run_harmony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68d32c43-1ff9-4dad-a0bc-c7acbf953420",
   "metadata": {},
   "outputs": [],
   "source": [
    "them_legend <- theme(\n",
    "  legend.position = \"inside\",\n",
    "  legend.justification = c(0, 0),\n",
    "    rect = element_rect(fill = \"transparent\")\n",
    ")\n",
    "Map_Seurat_cluster_run_harmony =  function(\n",
    "    adata,dims,\n",
    "    resolution,key_batch,\n",
    "    key_celltype=NULL,verbose=FALSE\n",
    "){\n",
    "    if(! key_batch %in% colnames(adata@meta.data)){\n",
    "        stop(sprintf(\"[Error] key_batch = %s is not in adata@meta.data\",key_batch))\n",
    "    }\n",
    "\n",
    "    adata@meta.data %>% count(.data[[key_batch]])\n",
    "    adata <- adata %>% RunHarmony(key_batch, plot_convergence = TRUE, \n",
    "                                  return.model = TRUE, verbose = verbose)\n",
    "    print(DimPlot(object = adata, reduction = \"pca\", group.by = key_batch,\n",
    "                  pt.size =2e4/nrow(adata@meta.data),) + them_legend)\n",
    "    print(DimPlot(object = adata, reduction = \"harmony\", group.by = key_batch,\n",
    "                  pt.size =2e4/nrow(adata@meta.data)) + them_legend)\n",
    "    \n",
    "    adata <- adata %>%\n",
    "      RunUMAP(reduction = \"harmony\", dims = dims, verbose = verbose) %>%\n",
    "      FindNeighbors(reduction = \"harmony\", dims = dims, verbose = verbose) %>%\n",
    "      FindClusters(resolution = resolution, verbose = verbose)\n",
    "    return(adata)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bc64d6-251f-47fa-8b25-ba9e33cff767",
   "metadata": {},
   "source": [
    "# Map_Seurat_mapquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bab4e510-fa78-436b-985a-e334bc3ef471",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# refdata =list(predicted.id = \"CL_cell_subtype1\")\n",
    "Map_Seurat_mapquery <-  function(adata_ref, adata_que, dims, refdata, reference.reduction = \"pca\",\n",
    "    verbose = FALSE\n",
    "\n",
    "    ) {\n",
    "  adata.anchors <- FindTransferAnchors(\n",
    "    reference = adata_ref, query = adata_que, dims = dims,\n",
    "    reference.reduction = reference.reduction, verbose = verbose\n",
    "  )\n",
    "  adata_que <- MapQuery(anchorset = adata.anchors, reference = adata_ref, query = adata_que,\n",
    "    refdata = refdata, reference.reduction = reference.reduction, reduction.model = \"umap\", verbose = verbose)\n",
    "  return(adata_que)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9cb7ae-d1e8-4567-baf1-70f4c3f06600",
   "metadata": {},
   "source": [
    "### F1-score\n",
    "\n",
    "```r\n",
    "# 使用\n",
    "cm = calculate_more_with_confusion_matrix(\n",
    "    calculate_confusion_matrix(actual,predicted)\n",
    ")\n",
    "cm\n",
    "calculate_accuracy_with_confusion_matrix(cm)\n",
    "calculate_F1Score_with_confusion_matrix(cm)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61b75aa6-ade8-4371-89c6-4ad5829199bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 计算混淆矩阵的函数  \n",
    "calculate_confusion_matrix <- function(y_true, y_pred) {  \n",
    "  classes <- sort(unique(c(y_true, y_pred)))  \n",
    "  matrix <- matrix(0, nrow = length(classes), ncol = length(classes), dimnames = list(classes, classes))  \n",
    "    \n",
    "  for (i in seq_along(y_true)) {  \n",
    "    matrix[y_true[i], y_pred[i]] <- matrix[y_true[i], y_pred[i]] + 1  \n",
    "  }  \n",
    "    \n",
    "  return(as.data.frame(matrix))  \n",
    "}  \n",
    "  \n",
    "# 计算精确度、精确度和召回率等指标的函数\n",
    "calculate_more_with_confusion_matrix <- function(data) {  \n",
    "    # data 为 calculate_confusion_matrix的运行结果\n",
    "  TP <- diag(as.matrix(data))  \n",
    "  FP <- colSums(data) - TP  \n",
    "  FN <- rowSums(data) - TP  \n",
    "  Precision <- TP / (TP + FP)  \n",
    "  Recall <- TP / (TP + FN)  \n",
    "  F1_Score <- 2 * (Precision * Recall) / (Precision + Recall)  \n",
    "    \n",
    "  df <- data.frame(TP, FP, FN,  \n",
    "                    Precision = ifelse(is.nan(Precision), 0, Precision),  \n",
    "                    Recall = ifelse(is.nan(Recall), 0, Recall),  \n",
    "                    F1_Score = ifelse(is.nan(F1_Score), 0, F1_Score))  \n",
    "    \n",
    "  return(df)  \n",
    "}  \n",
    "\n",
    "calculate_accuracy_with_confusion_matrix <- function(data) {  \n",
    "    # data 为 calculate_more_with_confusion_matrix的运行结果\n",
    "  accuracy <- sum(diag(as.matrix(data))) / sum(data)  \n",
    "  return(accuracy)  \n",
    "}\n",
    "\n",
    "calculate_F1Score_with_confusion_matrix <- function(data, average = \"weighted\") {  \n",
    "    # data 为 calculate_more_with_confusion_matrix的运行结果\n",
    "    \n",
    "  # 确保data是一个数据框，并且包含'TP', 'FP', 'FN'和'F1 Score'列  \n",
    "  if (!is.data.frame(data) || !all(c(\"TP\", \"FP\", \"FN\", \"F1_Score\") %in% names(data))) {  \n",
    "    stop(\"The data should be a data frame with columns 'TP', 'FP', 'FN', and 'F1_Score'.\")  \n",
    "  }  \n",
    "    \n",
    "  # 根据average参数计算F1分数  \n",
    "  if (average == \"macro\") {  \n",
    "    res <- mean(data$F1_Score)  \n",
    "  } else if (average == \"weighted\") {  \n",
    "    weights <- data$TP + data$FN  \n",
    "    res <- sum(data$F1_Score * weights) / sum(weights)  \n",
    "  } else if (average == \"micro\") {  \n",
    "    res <- 2 * sum(data$TP) / (2 * sum(data$TP) + sum(data$FP) + sum(data$FN))  \n",
    "  } else {  \n",
    "    stop(paste(\"[Error] Invalid average parameter:\", average))  \n",
    "  }  \n",
    "    \n",
    "  return(res)  \n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b759a0ae-b6a7-4e3e-a695-962811a92c01",
   "metadata": {},
   "source": [
    "### precess_after_Seurat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec4b2b47-5457-4dc8-8ff0-e99422e65604",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "precess_after_Seurat <- function(resdir, adata_ref, adt, adata_que, key_celltype, tissue_name, sp1, sp2) {\n",
    "  # adt@meta.data %>% head(2)\n",
    "  df_obs <-  bind_rows(\n",
    "\n",
    "    # ref\n",
    "    tibble(\n",
    "      cell_name = rownames(adata_ref@meta.data),\n",
    "      dataset = paste(tissue_name, sp1, sep = \"_\"),\n",
    "      cell_type = adata_ref@meta.data[[key_celltype]],\n",
    "      true_label = adata_ref@meta.data[[key_celltype]],\n",
    "      pre_label = rep(NA, adata_ref %>% Cells() %>% length()),\n",
    "      max_prob = rep(NA, adata_ref %>% Cells() %>% length()),\n",
    "      is_right = rep(NA, adata_ref %>% Cells() %>% length())\n",
    "    ),\n",
    "    # que\n",
    "    tibble(\n",
    "      cell_name = rownames(adt@meta.data),\n",
    "      dataset = paste(tissue_name, sp2, sep = \"_\"),\n",
    "      cell_type = adt@meta.data[[key_celltype]],\n",
    "      true_label = adt@meta.data[[key_celltype]],\n",
    "      pre_label = adt@meta.data[[\"predicted..\"]],\n",
    "      max_prob = adt@meta.data[[\"predicted...score\"]],\n",
    "      is_right = (true_label == pre_label)\n",
    "    )\n",
    "  )\n",
    "\n",
    "    df_umap <- bind_rows(\n",
    "      adata_ref@reductions$uma@cell.embeddings %>% as.data.frame()  %>% rename(\n",
    "        UMAP1 = umap_1,\n",
    "        UMAP2 = umap_2),\n",
    "      adt@reductions$ref.uma@cell.embeddings %>% as.data.frame() %>%  rename(\n",
    "        UMAP1 = refUMAP_1,\n",
    "        UMAP2 = refUMAP_2\n",
    "      )\n",
    "    )\n",
    "      df_umap <- df_umap %>% mutate(\n",
    "        cell_name = rownames(df_umap), .before = 1)\n",
    "#    df_umap <-  bind_rows(tibble(cell_name = Cells(adata_ref), UMAP1 = adata_ref$umap_1,\n",
    "#   UMAP2 = adata_ref$umap_2), adt@reductions$ref.uma@cell.embeddings %>% as.tibble() %>%  rename(\n",
    "#   UMAP1 = refUMAP_1,\n",
    "#   UMAP2 = refUMAP_2) %>% mutate(\n",
    "#   cell_name = rownames(adt@reductions$ref.uma@cell.embeddings)\n",
    "# )\n",
    "# )\n",
    "\n",
    "\n",
    "  df_obs <- df_obs %>% left_join(df_umap, by = c(\"cell_name\" = \"cell_name\"))\n",
    "  rm(df_umap)\n",
    "  # df_obs %>% head(2)\n",
    "  # [out] predicted_count_[que].csv\n",
    "  df_predicted_count <- df_obs %>% filter(dataset == sprintf(\"%s_%s\", tissue_name, sp2)) %>% group_by(true_label, pre_label) %>% count() %>% pivot_wider(\n",
    "    names_from = pre_label,\n",
    "    values_from  = n\n",
    "  )\n",
    "  df_predicted_count %>% write_csv(file.path(resdir, sprintf(\"predicted_count_%s.csv\", sp2)))\n",
    "\n",
    "  # df_predicted_count #%>%head(2)\n",
    "\n",
    "  # [out] ratio.csv\n",
    "  # tissue,type,sp,name,is_right_sum,is_right_count,ratio\n",
    "  df_ratio <- df_ratio <- df_obs %>% group_by(dataset) %>% summarise(\n",
    "    tissue = tissue_name,\n",
    "    type = \"species\",\n",
    "    sp = str_split(dataset, \"_\")[[1]][2],\n",
    "    name = \"\",\n",
    "    is_right_sum = length(is_right),\n",
    "    is_right_count = sum(is_right, na.rm = F),\n",
    "    ratio = is_right_count / is_right_sum\n",
    "\n",
    "  ) %>% select(-dataset)\n",
    "\n",
    "  df_ratio %>% write_csv(file.path(resdir, \"ratio.csv\"))\n",
    "  # [out] obs.csv\n",
    "  df_obs %>% write_csv(file.path(resdir, \"obs.csv\"))\n",
    "\n",
    "\n",
    "\n",
    "  # plot umap_dataset.png and umap_mapt.png\n",
    "  p_fig <- file.path(resdir, \"figs\")\n",
    "  if (!dir.exists(p_fig)) {\n",
    "    dir.create(p_fig)\n",
    "  }\n",
    "\n",
    "  temp_theme <- theme(\n",
    "    panel.background = element_blank(),\n",
    "    axis.line = element_line(),\n",
    "    legend.key = element_blank(),\n",
    "    legend.title = element_blank(),\n",
    "    # legend.text = element_text(size = 14)\n",
    "\n",
    "  )\n",
    "    \n",
    "    \n",
    "  p <- df_obs %>% ggplot(aes(x = UMAP1, y = UMAP2, color = dataset)) + geom_point(size = .5) + temp_theme\n",
    "  print(p)\n",
    "  ggsave(file.path(p_fig, \"umap_dataset.png\"), p, width = 110, height = 100, units = \"mm\")\n",
    "  p <- df_obs %>% ggplot(aes(x = UMAP1, y = UMAP2, color = cell_type)) + geom_point(size = .5) + temp_theme\n",
    "  print(p)\n",
    "  ggsave(file.path(p_fig, \"umap_umap.png\"), p, width = 110, height = 100, units = \"mm\")\n",
    "\n",
    "    # umap adata_ref seurat_clusters\n",
    "    p = DimPlot(adata_ref, group.by = c(key_celltype), reduction = \"umap\")\n",
    "    print(p)\n",
    "    ggsave(file.path(p_fig, sprintf(\"umap_ref_%s.png\",key_celltype)), p, width = 110, height = 100, units = \"mm\")\n",
    "    p = DimPlot(adata_ref, group.by = c(\"seurat_clusters\"), reduction = \"umap\")\n",
    "    print(p)\n",
    "    ggsave(file.path(p_fig, \"umap_ref_seurat_clusters.png\"), p, width = 110, height = 100, units = \"mm\")\n",
    "        \n",
    "    # ElbowPlot\n",
    "    p =   ElbowPlot(adata_ref, ndims = 50)\n",
    "    ggsave(file.path(p_fig, \"ElbowPlot_ref.png\"), p, width = 110, height = 100, units = \"mm\")\n",
    "\n",
    "\n",
    "    # calculate_confusion_matrix and F1-score\n",
    "    cm = calculate_more_with_confusion_matrix(\n",
    "    calculate_confusion_matrix(\n",
    "        filter(df_obs,dataset == paste(tissue_name, sp2, sep = \"_\"))$true_label,\n",
    "        filter(df_obs,dataset == paste(tissue_name, sp2, sep = \"_\"))$pre_label\n",
    "    )\n",
    ")\n",
    "    cat('[confusion_matrix] head\\n')\n",
    "    print(cm %>% head)\n",
    "\n",
    "    return(list(\n",
    "        weighted_F1  = calculate_F1Score_with_confusion_matrix(cm,average = \"weighted\")\n",
    "    )\n",
    "          )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6757816a-73e5-4567-81b5-f028293327c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### load_seuratobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e4bf777-8a96-4219-808c-925de5579388",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_seuratobj_add_obs <- function(p, adata, key_cell_name = \"cell_name\") {\n",
    "  if (file.exists(file.path(p, \"obs.csv\"))) {\n",
    "    df_obs <- read.csv(file.path(p, \"obs.csv\"), row.names = 1)\n",
    "    df_obs <- df_obs %>%\n",
    "      mutate(cell_name = rownames(df_obs))\n",
    "    adata@meta.data <- adata@meta.data %>%\n",
    "      mutate(cell_name = rownames(adata@meta.data), .before = 1) %>%\n",
    "      left_join(df_obs, by = c(cell_name = key_cell_name)) %>%\n",
    "      as.data.frame()\n",
    "    # left_join 返回tibble , index丢失了，加回来\n",
    "    rownames(adata@meta.data) <- adata@meta.data$cell_name\n",
    "\n",
    "  } else {\n",
    "    cat(sprintf(\"[not obs.csv] %s\\n\", p))\n",
    "  }\n",
    "  return(adata)\n",
    "}\n",
    "\n",
    "load_seuratobj <- function(p, return_matrix = FALSE, add_obs = TRUE, key_cell_name = \"cell_name\") {\n",
    "  adata <- Read10X(p)\n",
    "  if (adata %>% colnames() %>% str_detect('\"([^\"]+)\"') %>% all()) {\n",
    "    colnames(adata) <- str_extract(colnames(adata), '\"([^\"]+)\"', group = 1)\n",
    "  }\n",
    "  if (return_matrix) return(adata)\n",
    "  adata <- CreateSeuratObject(adata)\n",
    "  if (add_obs) {\n",
    "    adata <- load_seuratobj_add_obs(p, adata, key_cell_name = key_cell_name)\n",
    "  }\n",
    "  return(adata)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af5179e-721b-4a9c-bb62-422388b688af",
   "metadata": {},
   "source": [
    "### run_Seurat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec6296a4-b46c-4915-8674-b5d47a3caafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_Seurat <- function(\n",
    "    path_adata1,\n",
    "    path_adata2, path_varmap,\n",
    "    key_class1,\n",
    "    key_class2,\n",
    "    sp1,\n",
    "    sp2,\n",
    "    tissue_name,\n",
    "    dims,\n",
    "    resolution,\n",
    "    refdata,\n",
    "    aligned = FALSE,\n",
    "    resdir_tag = \"\",\n",
    "    resdir = \"/public/workspace/licanchengup/download/test/test_result\",\n",
    "    is_1v1 = TRUE,key_cell_name = \"cell_name\"\n",
    "    ) {\n",
    "  time_start <- as.numeric(Sys.time())\n",
    "  ## before run --------------------------------------------------\n",
    "  resdir <-  file.path(resdir, sprintf(\"%s_%s-corss-%s;%s\", tissue_name, sp1, sp2, resdir_tag))\n",
    "  # whether finish\n",
    "  if (file.exists(file.path(resdir, \"finish\"))) {\n",
    "    cat(sprintf(\"[has finish] %s\\n\", resdir))\n",
    "    return()\n",
    "  } else {\n",
    "    cat(sprintf(\"[start] %s\\n\", resdir))\n",
    "  }\n",
    "    \n",
    "  if (!dir.exists(resdir)) {\n",
    "    dir.create(resdir,recursive=TRUE)\n",
    "  }\n",
    "  key_celltype <- \"\"\n",
    "  if (key_class1 == key_class2) {\n",
    "    key_celltype <- key_class1\n",
    "  } else {\n",
    "    stop(sprintf(\"key_class1, key_class2 is not equal\\n %s != %s\", key_class1, key_class2))\n",
    "  }\n",
    "\n",
    "\n",
    "# load ref and que\n",
    "adata_ref <- load_seuratobj(path_adata1, return_matrix = TRUE, add_obs = FALSE)\n",
    "adata_que <- load_seuratobj(path_adata2, return_matrix = TRUE, add_obs = FALSE)\n",
    "\n",
    "#----------------------------------------\n",
    "## homology one2one for adata_que\n",
    "#----------------------------------------\n",
    "n_homology_noe2one_find <- 0\n",
    "n_homology_noe2one_use <- 0\n",
    "\n",
    "if (is_1v1) {\n",
    "\n",
    "df_varmap <- read_csv(path_varmap, na = \"\")[, 1:3]\n",
    "colnames(df_varmap) <- c(\"gn_ref\", \"gn_que\", \"homology_type\")\n",
    "# 去除na与重复项\n",
    "df_varmap <- df_varmap %>% filter(!is.na(gn_ref), !is.na(gn_que)) %>% distinct()\n",
    "keep= (df_varmap %>% transmute(\n",
    "gn_ref_is_unique = gn_ref %in% filter(df_varmap %>% group_by(gn_ref) %>% count() ,n == 1)$gn_ref,\n",
    "gn_que_is_unique = gn_que %in% filter(df_varmap %>% group_by(gn_que) %>% count() ,n == 1)$gn_que,\n",
    "keep = gn_ref_is_unique & gn_que_is_unique\n",
    "))$keep\n",
    "df_varmap = df_varmap[keep,] %>% filter(homology_type == 'ortholog_one2one')\n",
    "df_varmap <- tibble(\n",
    "gn_ref = rownames(adata_ref)\n",
    ") %>% left_join(df_varmap, by = \"gn_ref\")\n",
    "\n",
    "n_homology_noe2one_find <- df_varmap %>% filter(!is.na(gn_que)) %>% nrow()\n",
    "cat(sprintf(\"[homology one2one]find %d genes\\n\", n_homology_noe2one_find))\n",
    "# 没有配对的，使用ref的原名字\n",
    "# # ref_SNORD14E对上了que_SNORD14\n",
    "# # ref_SNORD14没对上，用原名字则导致que存在重复名字，故给没对上的加个前缀\n",
    "# # SNORD14\tSNORD14\tNA\n",
    "# # SNORD14E\tSNORD14\tortholog_one2one\n",
    "df_varmap <- df_varmap %>% mutate(\n",
    "gn_que = ifelse(is.na(gn_que), paste(\"not_o2o\", gn_ref, sep = \"_\"), gn_que)\n",
    ")\n",
    "\n",
    "if (!all(rownames(adata_ref) == df_varmap$gn_ref)) {\n",
    "stop(\"df_varmap$gn_ref not equal to rownames(adata)\")\n",
    "}\n",
    "if (df_varmap$gn_ref %>% duplicated %>% any | df_varmap$gn_que %>% duplicated %>% any) {\n",
    "stop(\"df_varmap$gn_ref or df_varmap$gn_que is duplicated\")\n",
    "}\n",
    "#--------------------\n",
    "# homology one2one gene name convert\n",
    "rownames(adata_ref)  <- df_varmap$gn_que\n",
    "#--------------------\n",
    "\n",
    "n_homology_noe2one_use <- intersect(\n",
    "rownames(adata_ref),\n",
    "rownames(adata_que)) %>% length()\n",
    "cat(sprintf(\"[homology one2one]use %d genes\\n\", n_homology_noe2one_use))\n",
    "\n",
    "}\n",
    "# add obs if it is exists\n",
    "adata_ref <- load_seuratobj_add_obs(path_adata1, CreateSeuratObject(adata_ref),key_cell_name =key_cell_name )\n",
    "adata_que <- load_seuratobj_add_obs(path_adata2, CreateSeuratObject(adata_que),key_cell_name =key_cell_name )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # [out] group_counts_unalign.csv\n",
    "  df_group_counts <- bind_rows(\n",
    "    # ref\n",
    "    tibble(\n",
    "      dataset = paste(tissue_name, sp1, sep = \"_\"),\n",
    "      cell_type = adata_ref@meta.data[[key_celltype]]\n",
    "    ),\n",
    "    # que\n",
    "    tibble(\n",
    "      dataset = paste(tissue_name, sp2, sep = \"_\"),\n",
    "      cell_type = adata_que@meta.data[[key_celltype]]\n",
    "  )) %>% group_by(dataset, cell_type) %>% count() %>% pivot_wider(\n",
    "    names_from = \"dataset\", values_from = \"n\"\n",
    "  )\n",
    "  df_group_counts %>% write_csv(file.path(resdir, \"group_counts_unalign.csv\"))\n",
    "  # process aligend\n",
    "  if (aligned) {\n",
    "    inter_celltype <- intersect(adata_ref@meta.data[[key_celltype]], adata_que@meta.data[[key_celltype]])\n",
    "    inter_celltype\n",
    "\n",
    "    adata_ref@meta.data <- adata_ref@meta.data %>% mutate(\n",
    "      in_inter_celltype__ = (.data[[key_celltype]] %in% inter_celltype)\n",
    "\n",
    "    )\n",
    "    adata_que@meta.data <- adata_que@meta.data %>% mutate(\n",
    "      in_inter_celltype__ = (.data[[key_celltype]] %in% inter_celltype)\n",
    "\n",
    "    )\n",
    "    adata_ref <- subset(adata_ref, in_inter_celltype__)\n",
    "    adata_que <- subset(adata_que, in_inter_celltype__)\n",
    "  }\n",
    "\n",
    "  df_group_counts <- bind_rows(\n",
    "    # ref\n",
    "    tibble(\n",
    "      dataset = paste(tissue_name, sp1, sep = \"_\"),\n",
    "      cell_type = adata_ref@meta.data[[key_celltype]]\n",
    "    ),\n",
    "    # que\n",
    "    tibble(\n",
    "      dataset = paste(tissue_name, sp2, sep = \"_\"),\n",
    "      cell_type = adata_que@meta.data[[key_celltype]]\n",
    "  )) %>% group_by(dataset, cell_type) %>% count() %>% pivot_wider(\n",
    "    names_from = \"dataset\", values_from = \"n\"\n",
    "  )\n",
    "  df_group_counts %>% write_csv(file.path(resdir, \"group_counts.csv\"))\n",
    "\n",
    "  time_before <- as.numeric(Sys.time())\n",
    "  ## run --------------------------------------------------\n",
    "  # for ref\n",
    "  # NormalizeData FindVariableFeatures ScaleData RunPCA\n",
    "  # ElbowPlot 决定 后续的dims\n",
    "  adata_ref <- Map_Seurat_normalize(adata_ref)\n",
    "  \n",
    "\n",
    "  # for ref\n",
    "  # FindNeighbors FindCluster RunUMAP(return.model = TRUE)\n",
    "  # RunUMAP返回umap model，后续的Running UMAP projection 需要umap model\n",
    "  # 调节dims, resolution\n",
    "  adata_ref <- Map_Seurat_cluster(adata_ref, dims = dims, resolution = resolution, key_celltype = key_celltype)\n",
    "  adata_ref\n",
    "\n",
    "  # [out] obs_ref.csv obs_que.csv\n",
    "  # obs_ref 中包含了 seurat_clusters\n",
    "  adata_ref@meta.data %>% write.csv(file.path(resdir, \"obs_ref.csv\"))\n",
    "  adata_que@meta.data %>% write.csv(file.path(resdir, \"obs_que.csv\"))\n",
    "  # for que\n",
    "  # NormalizeData FindVariableFeatures\n",
    "  adata_que <- Map_Seurat_normalize(adata_que, run_scale = FALSE, run_pca = FALSE)\n",
    "\n",
    "  # for ref and que\n",
    "  intersect_features <- intersect(Features(adata_ref), Features(adata_que))\n",
    "  cat(sprintf(\"[intersect features] is %d\\n\", intersect_features   %>% length()\n",
    "  ))\n",
    "\n",
    "  if (length(intersect_features) <= 20) {\n",
    "    cat(intersect_features, \"\\n\")\n",
    "  } else (\n",
    "    cat(\"[intersect_features][top 20]\\n\", intersect_features[1:20], \"\\n\")\n",
    "  )\n",
    "\n",
    "\n",
    "  # FindTransferAnchors MapQuery\n",
    "  adt <- Map_Seurat_mapquery(adata_ref, adata_que, dims = dims, refdata = refdata)\n",
    "  adt\n",
    "  adt@meta.data %>% head(2)\n",
    "\n",
    "  DimPlot(adt,\n",
    "    reduction = \"ref.umap\", group.by = key_celltype, label = FALSE, label.size = 3,\n",
    "    repel = TRUE\n",
    "  )\n",
    "  DimPlot(adt,\n",
    "    reduction = \"ref.umap\", group.by = \"predicted..\", label = FALSE, label.size = 3,\n",
    "    repel = TRUE\n",
    "  )\n",
    "\n",
    "  time_run <- as.numeric(Sys.time())\n",
    "\n",
    "  res_after = precess_after_Seurat(resdir, adata_ref, adt, adata_que, key_celltype, tissue_name, sp1, sp2)\n",
    "\n",
    "  time_end <- as.numeric(Sys.time())\n",
    "  write((sprintf(\n",
    "    \"[start] %f\n",
    "[finish before run]\\t%f\n",
    "[patameter][path_varmap]\\t%s\n",
    "[parameter][n_homology_noe2one_find]\\t%d\n",
    "[parameter][n_homology_noe2one_use]\\t%d\n",
    "[parameter][intersect_features_n]\\t%d\n",
    "[out][weighted_F1]\\t%f\n",
    "[finish run]\\t%f\n",
    "[end] %f\", \n",
    "      time_start, time_before, path_varmap,\n",
    "      n_homology_noe2one_find, n_homology_noe2one_use,\n",
    "      intersect_features %>% length(),\n",
    "      res_after[['weighted_F1']],time_run, time_end)),file.path(resdir, \"finish\"))\n",
    "  cat(sprintf(\"[has finish] %s\\n\", resdir))\n",
    "return(list(\n",
    "adata_ref=adata_ref, \n",
    "adata_que=adata_que, \n",
    "adt=adt\n",
    "\n",
    "))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3433f3-a4f0-45f1-805e-9ce5450a7123",
   "metadata": {},
   "source": [
    "### Map_Seurat_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb557152-d2c8-47b8-bb18-8b3c85ff8c20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Map_Seurat_example = function(Map_Seurat_example_index = NULL){\n",
    "Map_Seurat_example_1 = \"\n",
    "p_src <- '.'\n",
    "p_root <- './RA_h-corss-m;Seurat;AMP-Phase-1-map-GSE145286;CL_cell_subtype1'\n",
    "p_root\n",
    "path_adata1 <- file.path(p_src, 'AMP-Phase-1_human_fibroblast') # human\n",
    "path_adata2 <- file.path(p_src, 'GSE145286_mouse_fibroblast') # mouse\n",
    "\n",
    "# load ref and que --------------------------------------------------\n",
    "## load ref\n",
    "adata_ref <- load_seuratobj(path_adata1)\n",
    "adata_que <- load_seuratobj(path_adata2)\n",
    "\n",
    "# map  ------------------------------------------------------------\n",
    "# ref -> human\n",
    "# que -> mouse\n",
    "\n",
    "# for ref\n",
    "# NormalizeData FindVariableFeatures ScaleData RunPCA\n",
    "# ElbowPlot 决定 后续的dims\n",
    "adata_ref <- Map_Seurat_normalize(adata_ref)\n",
    "\n",
    "# for ref\n",
    "# FindNeighbors FindCluster RunUMAP(return.model = TRUE)\n",
    "# RunUMAP返回umap model，后续的Running UMAP projection 需要umap model\n",
    "# 调节dims, resolution\n",
    "\n",
    "adata_ref <- Map_Seurat_cluster(adata_ref, dims = 1:10, resolution = 0.1, key_celltype = 'CL_cell_subtype1')\n",
    "adata_ref\n",
    "\n",
    "# for que\n",
    "# NormalizeData FindVariableFeatures\n",
    "adata_que <- Map_Seurat_normalize(adata_que, run_scale = FALSE, run_pca = FALSE)\n",
    "\n",
    "# for ref and que\n",
    "# FindTransferAnchors MapQuery\n",
    "adata_res <- Map_Seurat_mapquery(adata_ref, adata_que, dims = 1:10, refdata = list('.' = 'CL_cell_subtype1'))\n",
    "adata_res\n",
    "adata_res@meta.data %>% head(2)\n",
    "\n",
    "adata_res@meta.data %>% head(2)\n",
    "\n",
    "DimPlot(adata_res,\n",
    "  reduction = 'ref.umap', group.by = 'CL_cell_subtype1', label = FALSE, label.size = 3,\n",
    "  repel = TRUE\n",
    ")\n",
    "DimPlot(adata_res,\n",
    "  reduction = 'ref.umap', group.by = 'predicted..', label = FALSE, label.size = 3,\n",
    "  repel = TRUE\n",
    ")\n",
    "\n",
    "\"\n",
    "    \n",
    "if(Map_Seurat_example_index == 1){\n",
    "    cat(Map_Seurat_example_1 )\n",
    "}else{\n",
    "    cat(\"Map_Seurat_example_index == 1\n",
    "> [simply]\n",
    "    use run_Seurat\n",
    "\n",
    "Map_Seurat_example_index == 2\n",
    "> [detail] \n",
    "    use Map_Seurat_normalize, Map_Seurat_cluster, Map_Seurat_mapquery\n",
    "\")\n",
    "    \n",
    "}\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9af9baf-fb61-495b-ac91-d5db22f0d192",
   "metadata": {},
   "source": [
    "# end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21d0cbee-3893-4c0f-9b5e-a34e88a79fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> function----------------------------------------\n",
      "serurat_to_mtx\n",
      "\n",
      "> Map_Seurat function-----------------------------\n",
      "Map_Seurat_normalize\n",
      "Map_Seurat_cluster\n",
      "Map_Seurat_mapquery\n",
      "precess_after_Seurat\n",
      "run_Seurat\t\t\t[simply]\n",
      "\n",
      "> other-------------------------------------------\n",
      "get_path_varmap\n"
     ]
    }
   ],
   "source": [
    "cat(\"\n",
    "> function----------------------------------------\n",
    "seurat_to_mtx\n",
    "\n",
    "> Map_Seurat function-----------------------------\n",
    "Map_Seurat_normalize\n",
    "Map_Seurat_cluster\n",
    "Map_Seurat_mapquery\n",
    "precess_after_Seurat\n",
    "run_Seurat\\t\\t\\t[simply]\n",
    "\n",
    "> other-------------------------------------------\n",
    "get_path_varmap\n",
    "show_\n",
    "savefig\n",
    "seurat_metadata_leftjoin\n",
    "seurat_gene_detect\n",
    "\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a276ee-b80b-4421-ba9d-16c2d500e779",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4a683d1-ce7f-45ee-b85c-7dfcfb6bd097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Map_Seurat_example(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a33dcda1-646d-4196-94d0-7c11f7dae859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# p_src <- '.'\n",
    "\n",
    "# path_adata1 <- file.path(p_src, 'AMP-Phase-1_human_fibroblast') # human\n",
    "# path_adata2 <- file.path(p_src, 'GSE145286_mouse_fibroblast') # mouse\n",
    "# key_class1 = 'CL_cell_subtype1'\n",
    "# key_class2 = 'CL_cell_subtype1'\n",
    "# # key_celltype <- 'CL_cell_subtype1'\n",
    "# sp1 <- 'h'\n",
    "# sp2 <- 'm'\n",
    "# tissue_name <- 'RA'\n",
    "# aligned= FALSE\n",
    "# refdata = list('.' = 'CL_cell_subtype1')\n",
    "# resdir_tag <- paste('Seurat', 'test_F', sep = ';')\n",
    "# resdir <- file.path('/public/workspace/licanchengup/link/disease/test_disease_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d4139e3-a6d5-4244-9da0-778f50c64b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = \"/public/workspace/ruru_97/projects/data/homo/biomart/input/human_to_mouse_1v1.txt\"\n",
    "# p = \"/public/workspace/ruru_97/projects/data/homo/biomart/input/human_to_mouse.txt\"\n",
    "# p = '/public/workspace/licanchengup/link/test/came_sample_data/gene_matches_mouse2human.csv'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R_publish",
   "language": "R",
   "name": "r_publish"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
